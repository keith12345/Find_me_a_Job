{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../Data/01_clean_sf_custom_ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3416"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 15951)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(max_df=0.95)\n",
    "tf_idf_vectorizer = tf_idf.fit(df.listed_items)\n",
    "tf_idf_array = tf_idf.fit_transform(df.listed_items).toarray()\n",
    "tf_idf_df = pd.DataFrame(tf_idf_array,columns=tf_idf.get_feature_names())\n",
    "tf_idf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "pickle_out = open('../Tools_and_models/tf_idf_model',\"wb\")\n",
    "pickle.dump(tf_idf, pickle_out)\n",
    "pickle_out.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "pickle_out = open('../Tools_and_models/tf_idf_vectorizer',\"wb\")\n",
    "pickle.dump(tf_idf_vectorizer, pickle_out)\n",
    "pickle_out.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['company_name', 'job_title', 'listed_items', 'posting_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>listed_items</th>\n",
       "      <th>posting_url</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000ad_hoc</th>\n",
       "      <th>000best_practice</th>\n",
       "      <th>000machine_learning</th>\n",
       "      <th>000skill_experience</th>\n",
       "      <th>...</th>\n",
       "      <th>zookeeperend_end</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoura</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurb</th>\n",
       "      <th>zvs</th>\n",
       "      <th>zweigwhite</th>\n",
       "      <th>zymergen</th>\n",
       "      <th>zymo</th>\n",
       "      <th>zynga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gap Inc. Corporate</td>\n",
       "      <td>Software Engineer, Price Execution</td>\n",
       "      <td>write build product according business need co...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=77d524a7cf198...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WrkShp</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>closely product assist investigation deep dive...</td>\n",
       "      <td>https://www.indeed.com/company/WrkShp/jobs/Bus...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 15955 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         company_name                           job_title  \\\n",
       "0  Gap Inc. Corporate  Software Engineer, Price Execution   \n",
       "1              WrkShp                    Business Analyst   \n",
       "\n",
       "                                        listed_items  \\\n",
       "0  write build product according business need co...   \n",
       "1  closely product assist investigation deep dive...   \n",
       "\n",
       "                                         posting_url   00  000  000ad_hoc  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=77d524a7cf198...  0.0  0.0        0.0   \n",
       "1  https://www.indeed.com/company/WrkShp/jobs/Bus...  0.0  0.0        0.0   \n",
       "\n",
       "   000best_practice  000machine_learning  000skill_experience  ...    \\\n",
       "0               0.0                  0.0                  0.0  ...     \n",
       "1               0.0                  0.0                  0.0  ...     \n",
       "\n",
       "   zookeeperend_end  zoom  zoura  zuckerberg  zurb  zvs  zweigwhite  zymergen  \\\n",
       "0               0.0   0.0    0.0         0.0   0.0  0.0         0.0       0.0   \n",
       "1               0.0   0.0    0.0         0.0   0.0  0.0         0.0       0.0   \n",
       "\n",
       "   zymo  zynga  \n",
       "0   0.0    0.0  \n",
       "1   0.0    0.0  \n",
       "\n",
       "[2 rows x 15955 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(tf_idf_df,left_index=True,right_index=True)\n",
    "df.to_pickle('../Data/01_tf_idf_and_features')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=10, random_state=42)\n",
    "nmf = nmf_model.fit_transform(tf_idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nmf\n",
    "H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The W factor contains the document membership weights relative to each of the k topics. Each row corresponds to a single document, and each column correspond to a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H factor contains the term weights relative to each of the k topics. In this case, each row corresponds to a topic, and each column corresponds to a unique term in the corpus vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 15951)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = np.argsort(H[1,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor(terms, H, topic_index, top):\n",
    "    #reverse sort the values to sort the indices\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append(terms[term_index])\n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "product customer technical team business market roadmap experience cross need\n",
      "Topic #1:\n",
      "experience system software technology java database test year service application\n",
      "Topic #2:\n",
      "cell biology assay experience laboratory molecular scientific method chemistry protein\n",
      "Topic #3:\n",
      "learning machine machine_learning model algorithm ml deep science deep_learning tensorflow\n",
      "Topic #4:\n",
      "benefit dental paid vision medical lunch employee insurance medical_dental commuter\n",
      "Topic #5:\n",
      "business analysis analytics insight sql model statistical experience tool quantitative\n",
      "Topic #6:\n",
      "project process management required ability support system requirement client business\n",
      "Topic #7:\n",
      "marketing sale content campaign market channel customer strategy digital skill\n",
      "Topic #8:\n",
      "design user research experience product designer visual web mobile interaction\n",
      "Topic #9:\n",
      "security network system infrastructure vulnerability incident threat cloud application linux\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf_model,tf_idf.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 15951)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(max_df=0.95)\n",
    "tf_idf_array = tf_idf.fit_transform(df.listed_items).toarray()\n",
    "tf_idf_df = pd.DataFrame(tf_idf_array,columns=tf_idf.get_feature_names())\n",
    "tf_idf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=15, random_state=42)\n",
    "nmf = nmf_model.fit_transform(tf_idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nmf\n",
    "H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The W factor contains the document membership weights relative to each of the k topics. Each row corresponds to a single document, and each column correspond to a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H factor contains the term weights relative to each of the k topics. In this case, each row corresponds to a topic, and each column corresponds to a unique term in the corpus vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15951)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = np.argsort(H[1,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor(terms, H, topic_index, top):\n",
    "    #reverse sort the values to sort the indices\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append(terms[term_index])\n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "product experience team roadmap engineering feature market cross product_management strategy\n",
      "Topic #1:\n",
      "learning machine machine_learning algorithm model ml deep deep_learning science tensorflow\n",
      "Topic #2:\n",
      "process project manufacturing system equipment quality control design material mechanical\n",
      "Topic #3:\n",
      "analysis analytics business insight statistical sql tool quantitative statistic model\n",
      "Topic #4:\n",
      "paid dental vision lunch insurance benefit medical company health flexible\n",
      "Topic #5:\n",
      "business project client management process solution ability functional requirement technology\n",
      "Topic #6:\n",
      "customer technical support sale service issue solution need provide software\n",
      "Topic #7:\n",
      "cell biology assay molecular scientific experience protein laboratory development method\n",
      "Topic #8:\n",
      "design user research visual designer experience interaction ux prototyping prototype\n",
      "Topic #9:\n",
      "security network system infrastructure vulnerability incident threat cloud linux application\n",
      "Topic #10:\n",
      "marketing sale content campaign market channel strategy digital medium enablement\n",
      "Topic #11:\n",
      "test experience web application testing software development javascript framework automation\n",
      "Topic #12:\n",
      "experience must skill ability required preferred year degree strong communication\n",
      "Topic #13:\n",
      "experience system pipeline spark aws distributed processing database hadoop infrastructure\n",
      "Topic #14:\n",
      "juul benefit committed boundless talented exceed subsidy bonus people supportive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf_model,tf_idf.get_feature_names(),10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 15951)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(max_df=0.95)\n",
    "tf_idf_array = tf_idf.fit_transform(df.listed_items).toarray()\n",
    "tf_idf_df = pd.DataFrame(tf_idf_array,columns=tf_idf.get_feature_names())\n",
    "tf_idf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=17, random_state=42)\n",
    "nmf = nmf_model.fit_transform(tf_idf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nmf\n",
    "H = nmf_model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The W factor contains the document membership weights relative to each of the k topics. Each row corresponds to a single document, and each column correspond to a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H factor contains the term weights relative to each of the k topics. In this case, each row corresponds to a topic, and each column corresponds to a unique term in the corpus vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 15951)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = np.argsort(H[1,:])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptor(terms, H, topic_index, top):\n",
    "    #reverse sort the values to sort the indices\n",
    "    top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append(terms[term_index])\n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "product team market roadmap feature cross product_management strategy define drive\n",
      "Topic #1:\n",
      "learning machine machine_learning model algorithm ml deep deep_learning tensorflow production\n",
      "Topic #2:\n",
      "process project manufacturing equipment system quality design material mechanical control\n",
      "Topic #3:\n",
      "analysis analytics insight business statistical sql tool quantitative statistic model\n",
      "Topic #4:\n",
      "paid dental lunch vision benefit insurance medical company health 401k\n",
      "Topic #5:\n",
      "business project management solution process requirement functional technical partner client\n",
      "Topic #6:\n",
      "skill ability must strong research communication client project excel detail\n",
      "Topic #7:\n",
      "cell biology assay molecular scientific experience laboratory protein biochemistry development\n",
      "Topic #8:\n",
      "design user research visual designer experience interaction ux prototyping prototype\n",
      "Topic #9:\n",
      "security network system infrastructure vulnerability incident threat cloud linux application\n",
      "Topic #10:\n",
      "marketing sale content campaign market channel strategy digital medium enablement\n",
      "Topic #11:\n",
      "customer technical support sale service issue solution need provide training\n",
      "Topic #12:\n",
      "test web testing application experience automation framework development javascript software\n",
      "Topic #13:\n",
      "experience system pipeline spark aws database distributed hadoop processing infrastructure\n",
      "Topic #14:\n",
      "juul benefit committed boundless talented exceed subsidy bonus supportive people\n",
      "Topic #15:\n",
      "required preferred year_preferred year united ge state insurance ca san\n",
      "Topic #16:\n",
      "experience science computer software engineering related technical field degree programming\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf_model,tf_idf.get_feature_names(),10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
